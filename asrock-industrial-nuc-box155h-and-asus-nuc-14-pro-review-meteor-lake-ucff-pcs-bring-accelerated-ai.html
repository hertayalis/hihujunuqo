<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=robots content="index,follow,noarchive"><title>AI Performance: UL Procyon AI Workloads - FluxBlog</title><meta name=description content="Drafting a set of benchmarks relevant to end-user AI use-cases has proved to be a challenging exercise. While training workloads are common in the datacenter and enterprise space, consumer workloads are focused on inference. In early days, the inferencing used to run in the cloud, but increasing privacy concerns, as well as the penalties associated"><meta name=author content="Some Person"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"FluxBlog","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"\/asrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html","name":"Ai performance ul procyon ai workloads"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Larita Shotwell"},"headline":"AI Performance: UL Procyon AI Workloads","description":"Drafting a set of benchmarks relevant to end-user AI use-cases has proved to be a challenging exercise. While training workloads are common in the datacenter and enterprise space, consumer workloads are focused on inference. In early days, the inferencing used to run in the cloud, but increasing privacy concerns, as well as the penalties associated","inLanguage":"en","wordCount":879,"datePublished":"2024-09-03T00:00:00","dateModified":"2024-09-03T00:00:00","image":"\/img\/avatar-icon.png","keywords":[""],"mainEntityOfPage":"\/asrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html","publisher":{"@type":"Organization","name":"\/","logo":{"@type":"ImageObject","url":"\/img\/avatar-icon.png","height":60,"width":60}}}</script><meta property="og:title" content="AI Performance: UL Procyon AI Workloads"><meta property="og:description" content="Drafting a set of benchmarks relevant to end-user AI use-cases has proved to be a challenging exercise. While training workloads are common in the datacenter and enterprise space, consumer workloads are focused on inference. In early days, the inferencing used to run in the cloud, but increasing privacy concerns, as well as the penalties associated"><meta property="og:image" content="/img/avatar-icon.png"><meta property="og:url" content="/asrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html"><meta property="og:type" content="website"><meta property="og:site_name" content="FluxBlog"><meta name=twitter:title content="AI Performance: UL Procyon AI Workloads"><meta name=twitter:description content="Drafting a set of benchmarks relevant to end-user AI use-cases has proved to be a challenging exercise. While training workloads are common in the datacenter and enterprise space, consumer workloads â€¦"><meta name=twitter:image content="/img/avatar-icon.png"><meta name=twitter:card content="summary"><meta name=twitter:site content="@username"><meta name=twitter:creator content="@username"><link href=./img/favicon.ico rel=icon type=image/x-icon><meta name=generator content="Hugo 0.98.0"><link rel=alternate href=./index.xml type=application/rss+xml title=FluxBlog><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css integrity=sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.5.0/css/all.css integrity=sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/main.css><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic"><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800"><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/highlight.min.css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/bh/css/codeblock.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css integrity=sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css integrity=sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R crossorigin=anonymous></head><body><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header class=header-section><div class="intro-header no-img"><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><h1>AI Performance: UL Procyon AI Workloads</h1><span class=post-meta><i class="fas fa-calendar"></i>&nbsp;Posted on September 3, 2024
&nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;5&nbsp;minutes
&nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;879&nbsp;words
&nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Larita Shotwell</span></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><article role=main class=blog-post><p>Drafting a set of benchmarks relevant to end-user AI use-cases has proved to be a challenging exercise. While training workloads are common in the datacenter and enterprise space, consumer workloads are focused on inference. In early days, the inferencing used to run in the cloud, but increasing privacy concerns, as well as the penalties associated with constant cloud communication, have contributed to the rise in demand for local inferencing capabilities. Additionally, generative AI (such as chatbots and image generators based on input prompts) has also garnered significant interest in recent days. Currently, most of these large-language models (LLMs) run in the cloud, as they are still too resource-heavy to run with reasonable performance in the systems of average users.</p><p>UL's Procyon AI benchmarks focuses on these workloads from an edge computing perspective. Broadly speaking, the benchmark is divided into two major components:</p><ul><li><a href=#>Computer Vision</a> (inference performance using six different neural network models)</li><li><a href=#>Generative AI</a> (image generation using the Stable Diffusion LLM)</li></ul><p>An attempt was made to process both benchmarks on the ASUS NUC14RVHv7 (Revel Canyon vPro) as well as the two configurations of the ASRock Industrial NUC BOX-155H as part of the evaluation of its capabilities as an "AI PC". The results are summarized in the remainder of this section.</p><h3>Computer Vision Neural Networks Performance</h3><p>The six supported neural networks were benchmarked with the following configurations:</p><ul><li>OpenVINO CPU with float32 precision</li><li>OpenVINO GPU with float16 precision</li><li>OpenVINO GPU with float32 precision</li><li>OpenVINO GPU With integer precision</li><li>OpenVINO NPU with float16 precision</li><li>OpenVINO NPU with integer precision</li><li>WinML GPU with float16 precision</li><li>WinML GPU with float32 precision</li><li>WinML GPU with integer precision</li></ul><p>The OpenVINO configurations can be evaluated only on systems with an Intel CPU or GPU or NPU. In general, a neural network model's accuracy / quality of results improves with precision. In other words, we expect float16 to deliver better results than integer, and float32 to be better than float16. However, increased precision requires more complex calculations and that results in higher power consumption. As general purpose engines, the CPU is expected to be the most power hungry of the lot, while the NPUs which are purpose-built for neural network acceleration are expected to be better than the GPU configurations. UL has a <a href=#>detailed study of the variation in the quality of results</a> with precision for different networks in their benchmark resources section.</p><p>The YOLO V3 network is used for real-time object detection in videos. The graphs below show that at the same precision, OpenVINO performs better than WinML on the GPU. Additionally, for the same precision, OpenVINO performs better on the GPU rather than the NPU.</p><p align=center><img id=imageULPAIYOLOAIT src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-average-inference-time---openvino-cpu-f32-yolo-v3.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The REAL ESRGAN network is used for upscaling images / restoration of videos and pictures. Relative performance for different precisions / execution hardware is similar to what was seen for the YOLO V3 network.</p><p align=center><img id=imageULPAIRLESRGANAIT src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-average-inference-time---openvino-cpu-f32-real-esrgan.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The ResNet 50 network is primarily used for image classification. Again, we see the NPU being slower than the GPU at the same precision, while WinML lags behind OpenVINO for the same underlying execution hardware and precision.</p><p align=center><img id=imageULPAIRSNTAIT src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-average-inference-time---openvino-cpu-f32-resnet-50.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The MobileNet V3 network is used, among other things, for image processing tasks such as tilt correction. Similar to the other networks, WinML again lags behind OpenVINO. However, the NPU is faster than the GPU for the same precision network.</p><p align=center><img id=imageULPAIMBLNTAIT src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-average-inference-time---openvino-cpu-f32-mobilenet-v3.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The Inception V4 network, like the ResNet 50, is primarily used for image classification. Similar to most other networks, WinML performance is not as good as with OpenVINO, and the NPU is slower than the GPU for the same precision.</p><p align=center><img id=imageULPAIINCPTAIT src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-average-inference-time---openvino-cpu-f32-inception-v4.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The DeepLab V3 network is used for image segmentation. In other words, it identifies groups of pixels in an image that satisfies specific requirements. The NPU is almost 4x slower than the GPU for the same precision and network. OpenVINO continues to perform better than WinML for the same precision network/</p><p align=center><img id=imageULPAIDLV3AIT src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-average-inference-time---openvino-cpu-f32-deeplab-v3.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The UL Procyon AI Computer Vision benchmark run processes each model for 3 minutes, maintaining a count of inferences as well as the average time taken for each inference. It presents an overall score for all six models together, though it is possible that some networks perform better than others for the same hardware / precision configuration.</p><p align=center><img id=imageULPAIOVRLSCR src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-overall-score---cv-openvino-cpu-f32.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>The Revel Canyon NUC comes out on top in the CPU-only OpenVINO run with float32 precision. For the OpenVINO GPU runs, the NUC BOX-155H manages to sneak in a slight lead over the other systems. Finally, WinML performance is quite bad compared to OpenVINO.</p><p>The benchmark runs for a fixed time. Hence, instead of tracking energy consumption, we opt to report the average at-wall power consumption for the system as a whole for each run set.</p><p align=center><img id=imageULPAICVPWR src=https://cdn.statically.io/img/images.anandtech.com/graphs/graph21398/ul_procyon_ai_ulp-average-power-consumption---cv-openvino-cpu-f32.png width=100% style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></p><p>As expected, the NPU is the most power-efficient of the lot. Higher precision translates to higher power consumption, and CPU mode is the least power-efficient.</p><h3>Generative AI Performance</h3><p>The Stability Diffusion prompt used for benchmarking in UL Procyon AI generates 16 different images. However, on all three system configurations, the benchmark crashed after generating 3 or 4 images. This benchmark is meant for high-end systems with discrete GPUs, and hence we didn't bother to follow up on the crashes.</p><p>As we get more systems processed with the UL Procyon AI benchmark, an attempt will be made to get the Generative AI benchmark working on them.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH9yf5hxZpqroqSwrHnIp5uuq6SntqK4jKesnGWSpMVygZShZJqmlGKutMHSZqWum11mgW680ahkq52mnrK4ecyeq56nomK5orfEZqycnpZivaS%2FjJupoqaXYq6kr8SlnKuZpJqxbq3IaG0%3D</p><hr><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><ul class=share><li><a href="//twitter.com/share?url=%2fasrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html&text=AI%20Performance%3a%20UL%20Procyon%20AI%20Workloads&via=username" target=_blank title="Share on Twitter"><i class="fab fa-twitter"></i></a></li><li><a href="//www.facebook.com/sharer/sharer.php?u=%2fasrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html" target=_blank title="Share on Facebook"><i class="fab fa-facebook"></i></a></li><li><a href="//reddit.com/submit?url=%2fasrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html&title=AI%20Performance%3a%20UL%20Procyon%20AI%20Workloads" target=_blank title="Share on Reddit"><i class="fab fa-reddit"></i></a></li><li><a href="//www.linkedin.com/shareArticle?url=%2fasrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html&title=AI%20Performance%3a%20UL%20Procyon%20AI%20Workloads" target=_blank title="Share on LinkedIn"><i class="fab fa-linkedin"></i></a></li><li><a href="//www.stumbleupon.com/submit?url=%2fasrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html&title=AI%20Performance%3a%20UL%20Procyon%20AI%20Workloads" target=_blank title="Share on StumbleUpon"><i class="fab fa-stumbleupon"></i></a></li><li><a href="//www.pinterest.com/pin/create/button/?url=%2fasrock-industrial-nuc-box155h-and-asus-nuc-14-pro-review-meteor-lake-ucff-pcs-bring-accelerated-ai.html&description=AI%20Performance%3a%20UL%20Procyon%20AI%20Workloads" target=_blank title="Share on Pinterest"><i class="fab fa-pinterest"></i></a></li></ul></div></div></section></article><ul class="pager blog-pager"><li class=previous><a href=./chris-odonnell-net-worth-2024-2.html data-toggle=tooltip data-placement=top title="Chris ODonnell Net Worth 2024">&larr; Previous Post</a></li><li class=next><a href=./a-bootleg-marvel-movie-endorsed-by-the-mcus-spider-man-director-lands-in-a-month-but-nobody-cares-for-obvious-reasons.html data-toggle=tooltip data-placement=top title="A bootleg Marvel movie endorsed by the MCUs Spider-Man director lands in a month, but nobod">Next Post &rarr;</a></li></ul></div></div></div><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href title=RSS><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="credits copyright text-muted">All rights reserved
&nbsp;&bull;&nbsp;&copy;
2024
&nbsp;&bull;&nbsp;
<a href=./>FluxBlog</a></p><p class="credits theme-by text-muted"><a href=https://gohugo.io>Hugo v0.98.0</a> powered &nbsp;&bull;&nbsp; Theme <a href=https://github.com/halogenica/beautifulhugo>Beautiful Hugo</a> adapted from <a href=https://deanattali.com/beautiful-jekyll/>Beautiful Jekyll</a></p></div></div></div></footer><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js integrity=sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js integrity=sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe crossorigin=anonymous></script>
<script src=https://code.jquery.com/jquery-1.12.4.min.js integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin=anonymous></script>
<script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/main.js></script>
<script src=https://assets.cdnweb.info/hugo/bh/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script>renderMathInElement(document.body)</script><script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js integrity=sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js integrity=sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q crossorigin=anonymous></script><script src=https://assets.cdnweb.info/hugo/bh/js/load-photoswipe.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>